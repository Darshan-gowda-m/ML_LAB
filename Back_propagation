import random
import math
from sklearn.model_selection import train_test_split

class SimpleNeuralNetwork:
    def __init__(self, n_inputs, n_hidden, n_outputs):
        self.network = []
        hidden_layer = [{'weights': [random.uniform(-1, 1) for _ in range(n_inputs + 1)]} for _ in range(n_hidden)]
        self.network.append(hidden_layer)
        output_layer = [{'weights': [random.uniform(-1, 1) for _ in range(n_hidden + 1)]} for _ in range(n_outputs)]
        self.network.append(output_layer)
    
    def sigmoid(self, x):
        return 1 / (1 + math.exp(-x))
    
    def forward_propagate(self, inputs):
        for layer in self.network:
            new_inputs = []
            for neuron in layer:
                activation = neuron['weights'][-1]  # bias
                for i in range(len(neuron['weights']) - 1):
                    activation += neuron['weights'][i] * inputs[i]
                neuron['output'] = self.sigmoid(activation)
                new_inputs.append(neuron['output'])
            inputs = new_inputs
        return inputs

    def backward_propagate_error(self, expected):
        for i in reversed(range(len(self.network))):
            layer = self.network[i]
            errors = []
            if i == len(self.network) - 1:
                for j in range(len(layer)):
                    neuron = layer[j]
                    errors.append(expected[j] - neuron['output'])
            else:
                for j in range(len(layer)):
                    error = 0.0
                    for neuron in self.network[i + 1]:
                        error += neuron['weights'][j] * neuron['delta']
                    errors.append(error)
            for j in range(len(layer)):
                neuron = layer[j]
                neuron['delta'] = errors[j] * neuron['output'] * (1 - neuron['output'])

    def update_weights(self, inputs, lrate):
        for i in range(len(self.network)):
            if i != 0:
                inputs = [neuron['output'] for neuron in self.network[i - 1]]
            for neuron in self.network[i]:
                for j in range(len(inputs)):
                    neuron['weights'][j] += lrate * neuron['delta'] * inputs[j]
                neuron['weights'][-1] += lrate * neuron['delta']  # bias

    def train(self, train_data, lrate, n_epoch):
        for epoch in range(n_epoch):
            sum_error = 0
            for row in train_data:
                inputs = row[:-1]
                expected = row[-1]
                outputs = self.forward_propagate(inputs)
                sum_error += sum([(expected[i] - outputs[i]) ** 2 for i in range(len(expected))])
                self.backward_propagate_error(expected)
                self.update_weights(inputs, lrate)
            if epoch % 1000 == 0 or epoch == n_epoch - 1:
                print(f">epoch={epoch}, lrate={lrate:.3f}, error={sum_error:.6f}")

    def predict(self, inputs):
        outputs = self.forward_propagate(inputs)
        return [round(output) for output in outputs]


# === MAIN EXECUTION ===
if __name__ == "__main__":
    # Base XOR dataset
    train_data = [
        [0, 0, [0]],
        [0, 1, [1]],
        [1, 0, [1]],
        [1, 1, [0]]
    ]

    n_inputs = len(train_data[0]) - 1
    n_outputs = len(train_data[0][-1])
    model = SimpleNeuralNetwork(n_inputs, 2, n_outputs)

    # Train the model
    model.train(train_data, lrate=0.1, n_epoch=10000)

    # === Additional Test Dataset (10+ examples) ===
    test_data = [
        [0, 1, [1]], [1, 0, [1]], [1, 1, [0]], [0, 0, [0]],
        [0.1, 0.9, [1]], [0.9, 0.1, [1]], [0.2, 0.2, [0]],
        [0.5, 0.5, [0]], [0.7, 0.3, [1]], [0.3, 0.7, [1]]
    ]

    print("\n=== Test Set Evaluation (10+ samples) ===")
    correct = 0
    for row in test_data:
        inputs = row[:-1]
        expected = row[-1]
        predicted = model.predict(inputs)
        is_correct = predicted == expected
        correct += is_correct
        print(f"Input={inputs}, Expected={expected}, Predicted={predicted}, Correct={is_correct}")
    print(f"Test Accuracy: {(correct / len(test_data)) * 100:.2f}%")

    # === User Input for Prediction ===
    print("\n=== Predict Custom Input (x y) ===")
    while True:
        try:
            user_input = input("Enter inputs (x y) or 'q' to quit: ").strip()
            if user_input.lower() == 'q':
                break
            x, y = map(float, user_input.split())
            result = model.predict([x, y])
            print(f"Predicted Output: {result[0]}")
        except Exception as e:
            print(f"Invalid input. Try again. ({e})")

    # === Final Weights Display ===
    print("\n=== Final Weights ===")
    for i, layer in enumerate(model.network):
        print(f"Layer {i+1}:")
        for j, neuron in enumerate(layer):
            print(f"  Neuron {j+1} weights: {neuron['weights']}")
